{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0bK-S4uegKm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install tensorflow==2.12\n",
        "!pip install keras==2.12"
      ],
      "metadata": {
        "id": "ftlwlSGcK9Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "EdaGezB1K9Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report, roc_curve\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  *\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as mpimg\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "CDWIclTtK9Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install imutils library\n",
        "!pip install imutils"
      ],
      "metadata": {
        "id": "RH-svjpFK9Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the files in the directory\n",
        "os.listdir('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling')"
      ],
      "metadata": {
        "id": "3h7Qe-a2K9Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#showing image of normal\n",
        "im = Image.open('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/normal/result_r1_Im003.png').resize((255, 255))\n",
        "im"
      ],
      "metadata": {
        "id": "MDySir0lK9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#showing image of glaucoma\n",
        "im = Image.open('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/glaucoma/result_r1_Im118.png').resize((255, 255))\n",
        "im"
      ],
      "metadata": {
        "id": "KDxJx0ipK9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the directory of our data\n",
        "glaucoma = os.listdir('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/glaucoma')\n",
        "normal = os.listdir('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/normal')\n",
        "\n",
        "#concate two data\n",
        "data = np.concatenate([glaucoma,normal])\n",
        "assert (len(data) == len(glaucoma)+len(normal))\n",
        "\n",
        "#mapping our classes to 1 and 0. 1 == glaucoma and 0 == normal\n",
        "target_x = np.full(len(glaucoma),1)\n",
        "target_y = np.full(len(normal),0)\n",
        "\n",
        "#label of our data\n",
        "data_target = np.concatenate([target_x,target_y])\n",
        "\n",
        "assert (len(data_target) == len(target_x)+len(target_y))\n",
        "assert (len(data_target) == len(data))\n",
        "\n",
        "print(len(target_x), len(target_y))"
      ],
      "metadata": {
        "id": "Cxcy9CTsK9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the height and width of the image for our model\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "IMAGE_SIZE = [IMG_HEIGHT, IMG_WIDTH]"
      ],
      "metadata": {
        "id": "6VLqk-bnK9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_data = []\n",
        "\n",
        "# Reading images from the glaucoma directory, resizing, preprocessing, and appending to the list\n",
        "for file in glaucoma:\n",
        "    img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/glaucoma/' + file)\n",
        "    img2 = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
        "    #preprocessed_img = preprocess_image(img2)\n",
        "    #X_data.append(preprocessed_img)\n",
        "    X_data.append(img2)\n",
        "\n",
        "# Reading images from the normal directory, resizing, preprocessing, and appending to the list\n",
        "for file in normal:\n",
        "    img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Project Implementation/RIM ONE DL_Data cleaning/RIM ONE DL _after_downsampling/normal/' + file)\n",
        "    img2 = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
        "    #preprocessed_img = preprocess_image(img2)\n",
        "    #X_data.append(preprocessed_img)\n",
        "    X_data.append(img2)\n",
        "\n",
        "X_data = np.squeeze(X_data)\n",
        "assert (len(X_data) == len(data) == len(data_target))\n"
      ],
      "metadata": {
        "id": "nR4Lv5LXK9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "X = X_data.astype('float32')\n",
        "X /= 255"
      ],
      "metadata": {
        "id": "R6UWrSHtK9Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data.shape"
      ],
      "metadata": {
        "id": "nWWyKt6fK9Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into 75:15:15 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data_target, random_state=50, test_size=0.15, stratify = data_target)\n",
        "\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "id": "Di40EyVaK9Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I add\n",
        "#sample of training data\n",
        "import matplotlib.pyplot as plt\n",
        "num_samples = 5\n",
        "fig, axs = plt.subplots(1, num_samples, figsize=(10, 4))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    axs[i].imshow(cv2.cvtColor(X_train[i], cv2.COLOR_BGR2RGB))  # Assuming grayscale images\n",
        "    axs[i].set_title(''.format(i))\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJ-73yMcK9Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n",
        "#define input shape\n",
        "input_shape = (224,224,3)#DenseNet121, VGG19, ResNet50\n",
        "\n",
        "#get the pretrained model\n",
        "base_model = tf.keras.applications.ResNet50(input_shape= input_shape,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "#set the trainable method of covolution layer as false\n",
        "# why set to false?? because we don't want to mess up the pretrained weights of the model!!\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "NVuBiCTBK9Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the base model to the sequential model\n",
        "model.add(base_model)\n",
        "\n",
        "# Add a batch normalization layer to the sequential model\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add a dropout layer with rate 0.3 to the sequential model\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Add a dense layer with 256 units and ReLU activation function to the sequential model\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Add a flatten layer to the sequential model\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a dropout layer with rate 0.5 to the sequential model\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add a dense layer with 128 units and ReLU activation function to the sequential model\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "-8lW19Z7K9Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),#lr=0.01\n",
        "    metrics=[\"acc\"]\n",
        ")"
      ],
      "metadata": {
        "id": "dE9xEE_QK9Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint which stores the weights of the model when maximum validation accuracy is found\n",
        "checkpoint_filepath = \"/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/checkpoint_RIM-ONE DL/Classification_DenseNet121_RIM-ONE DL_15_batch_8_epoch_weights.best.hdf5\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size = 8,\n",
        "                    epochs = 15, validation_split = 0.18, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "vVOCwoKaK9Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/Saved_model_RIM-ONE_DL/Classification_DenseNet121_RIM-ONE DL_epoch_15_batch_8_lr=0.01_model.h5')"
      ],
      "metadata": {
        "id": "jhSity55K9Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history.history\n",
        "\n",
        "train_loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "train_acc = history['acc']\n",
        "val_acc = history['val_acc']\n",
        "\n",
        "\n",
        "# Loss\n",
        "plt.figure()\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_15_batch_8_epoch_lr=0.01_loss_graph.png')#add\n",
        "plt.show()\n",
        "\n",
        "# Accuracy#\n",
        "plt.figure()\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_15_batch_8_epoch_lr=0.01_accuracy_graph.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nH7iMd0bK9Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the history\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/saved history/Classification_ResNet50_epoch_15_batch_8_lr=0.01_history.pickle', 'wb') as file:\n",
        "    pickle.dump(history, file)"
      ],
      "metadata": {
        "id": "njDlmzCiK9Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "0E0I-viZtGUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history.history\n",
        "\n",
        "train_loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "train_acc = history['acc']\n",
        "val_acc = history['val_acc']\n",
        "\n",
        "\n",
        "# Loss\n",
        "plt.figure()\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_15_batch_8_epoch_lr=0.01_loss_graph.png')#add\n",
        "plt.show()\n",
        "\n",
        "# Accuracy#\n",
        "plt.figure()\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_15_batch_8_epoch_lr=0.01_accuracy_graph.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fg5gnNETsTRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the history\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/saved history/Classification_ResNet50_epoch_15_batch_8_lr=0.01_history.pickle', 'wb') as file:\n",
        "    pickle.dump(history, file)"
      ],
      "metadata": {
        "id": "oCRCdHKEtQTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "s4Qt5snkVouI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(X_test)\n",
        "y_pred = [1 if x >= 0.5 else 0 for x in y_hat]\n",
        "\n",
        "#metrics calculation\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)\n",
        "\n",
        "# specificity calculation\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "specificity = tn / (tn+fp)\n",
        "print('Specificity: ',specificity)\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#To save\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert report to a DataFrame for visualization\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Plot classification report\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_report.iloc[:-1, :].T, annot=True, cmap='Blues')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "\n",
        "# Save classification report as image\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_epoch_15_early_14_batch_8_lr=0.001_classification_report.png')\n"
      ],
      "metadata": {
        "id": "tbaqehKUtQbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "categories = ['Normal', 'Glaucoma']\n",
        "df_matrix = pd.DataFrame(matrix, index = categories, columns = categories)\n",
        "sns.heatmap(df_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/ClassificationResNet50_RIM-ONE DL_epoch_15_early_14_batch_8_lr=0.001_confusion_matrix.png')"
      ],
      "metadata": {
        "id": "ATHtLTubtdKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC Curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='ResNet50_')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/Project Implementation/Classification/graphes_RIM-ONE_DL/Classification_ResNet50_RIM-ONE DL_epoch_15_early_14_batch_8_lr=0.001_ROC Curve_graph.png')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "6p9m8pEvtdOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set\n",
        "\n",
        "#Check the confusion matrix for various thresholds. Which one is good?\n",
        "#Need to balance positive, negative, false positive and false negative.\n",
        "#ROC can help identify the right threshold.\n",
        "##################################################################\n",
        "\"\"\"\n",
        "Receiver Operating Characteristic (ROC) Curve is a plot that helps us\n",
        "visualize the performance of a binary classifier when the threshold is varied.\n",
        "\"\"\"\n",
        "#ROC\n",
        "from sklearn.metrics import roc_curve\n",
        "y_preds = model.predict(X_test).ravel()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'y--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8CCEbc6lGfmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set\n",
        "\n",
        "#AUC\n",
        "#Area under the curve (AUC) for ROC plot can be used to understand hpw well a classifier\n",
        "#is performing.\n",
        "#% chance that the model can distinguish between positive and negative classes.\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_value = auc(fpr, tpr)\n",
        "print(\"Area under curve, AUC = \", auc_value)"
      ],
      "metadata": {
        "id": "xa5Ur7ujUXuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}